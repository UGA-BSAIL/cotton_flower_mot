{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64c3214-c2ab-463a-840c-a14c8a70ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "from spektral import datasets\n",
    "from spektral.layers import CensNetConv\n",
    "\n",
    "# Load the citation data.\n",
    "dataset = datasets.citation.Citation(\"cora\", normalize_x=True, random_splits=False)\n",
    "cora = dataset.read()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c82e46-ccf7-4c63-84c1-b3fdf9dfd33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 16:50:48.515342: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-30 16:50:48.515366: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-30 16:50:48.515381: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (twilight-sparkle): /proc/driver/nvidia/version does not exist\n",
      "2022-06-30 16:50:48.515574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert citation graph into an undirected graph.\n",
    "adjacency = cora.a.todense()\n",
    "adjacency_upper = tf.linalg.band_part(adjacency, 0, -1)\n",
    "adjacency_lower = tf.linalg.band_part(adjacency, -1, 0)\n",
    "\n",
    "adjacency_upper_symmetric = adjacency_upper + tf.transpose(adjacency_upper)\n",
    "adjacency_lower_symmetric = adjacency_lower + tf.transpose(adjacency_lower)\n",
    "adjacency_undirected = tf.maximum(adjacency_upper_symmetric, adjacency_lower_symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da84277e-a31f-4ce6-8e89-24bb62f032ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cotton_flower_mot.pipelines.model_training.graph_utils import compute_pairwise_similarities\n",
    "from cotton_flower_mot.pipelines.model_training.similarity_utils import cosine_similarity\n",
    "from spektral.data import Graph\n",
    "tf.keras.mixed_precision.set_global_policy(\"float32\")\n",
    "\n",
    "# Compute edge features.\n",
    "connected_node_indices = tf.where(adjacency_upper)\n",
    "# Get the corresponding node features for each edge.\n",
    "left_node_features = tf.gather(cora.x, connected_node_indices[:, 0])\n",
    "right_node_features = tf.gather(cora.x, connected_node_indices[:, 1])\n",
    "# Compute cosine similarities for each edge.\n",
    "cosine_similarities = cosine_similarity(left_node_features, right_node_features)\n",
    "\n",
    "edge_features = tf.expand_dims(cosine_similarities, -1)\n",
    "cora = Graph(x=cora.x, a=cora.a, e=edge_features.numpy(), y=cora.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d908ac0-865a-4c39-9612-12d1df82d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model, layers\n",
    "from spektral.layers import CensNetConv\n",
    "\n",
    "# Build the model.\n",
    "node_features = Input(shape=(cora.n_node_features,))\n",
    "edge_features = Input(shape=(cora.n_edge_features,))\n",
    "node_laplacian = Input(shape=(cora.n_nodes,))\n",
    "# The undirected graph means that the number of edges is doubled.\n",
    "edge_laplacian = Input(shape=(cora.n_edges // 2,))\n",
    "incidence = Input(shape=(cora.n_edges // 2,))\n",
    "\n",
    "static_features = (node_laplacian, edge_laplacian, incidence)\n",
    "\n",
    "nodes_2, edges_2 = CensNetConv(64, 64, activation=\"relu\")((node_features, static_features, edge_features))\n",
    "nodes_2 = layers.Dropout(0.5)(nodes_2)\n",
    "edges_2 = layers.Dropout(0.5)(edges_2)\n",
    "nodes_3, _ = CensNetConv(64, 64, activation=\"relu\")((nodes_2, static_features, edges_2))\n",
    "nodes_3 = layers.Dropout(0.5)(nodes_3)\n",
    "# Apply the classification.\n",
    "node_class = layers.Dense(cora.n_labels, activation=\"softmax\")(nodes_3)\n",
    "\n",
    "model = Model(inputs=[node_features, edge_features, node_laplacian, edge_laplacian, incidence], outputs=[node_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a6f7aa-6954-4e87-84df-389595705c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data.loaders import SingleLoader\n",
    "import numpy as np\n",
    "\n",
    "# Prepare for training.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(reduction=\"sum\"),\n",
    "              weighted_metrics=[\"acc\"])\n",
    "\n",
    "# We convert the binary masks to sample weights so that we can compute the\n",
    "# average loss over the nodes (following original implementation by\n",
    "# Kipf & Welling)\n",
    "def mask_to_weights(mask):\n",
    "    return mask.astype(np.float32) / np.count_nonzero(mask)\n",
    "\n",
    "\n",
    "weights_tr, weights_va, weights_te = (\n",
    "    mask_to_weights(mask)\n",
    "    for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
    ")\n",
    "\n",
    "node_laplacian, edge_laplacian, incidence = CensNetConv.preprocess(cora.a.todense())\n",
    "\n",
    "inputs_and_targets = ((cora.x, cora.e, node_laplacian, edge_laplacian, incidence), cora.y)\n",
    "training_dataset = tf.data.Dataset.from_tensors(inputs_and_targets + (weights_tr,))\n",
    "testing_dataset = tf.data.Dataset.from_tensors(inputs_and_targets + (weights_te,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1b537f-7810-4078-8493-a25b774189d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2022-06-30 16:51:20,539 - tensorflow - WARNING - Gradients do not exist for variables ['cens_net_conv_1/edge_kernel:0', 'cens_net_conv_1/node_weights:0', 'cens_net_conv_1/edge_bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2022-06-30 16:51:20,698 - tensorflow - WARNING - Gradients do not exist for variables ['cens_net_conv_1/edge_kernel:0', 'cens_net_conv_1/node_weights:0', 'cens_net_conv_1/edge_bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9459 - acc: 0.1071 - val_loss: 1.9433 - val_acc: 0.3190\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9469 - acc: 0.1286 - val_loss: 1.9451 - val_acc: 0.1030\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9450 - acc: 0.1857 - val_loss: 1.9461 - val_acc: 0.0910\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9453 - acc: 0.1857 - val_loss: 1.9464 - val_acc: 0.0910\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9479 - acc: 0.1214 - val_loss: 1.9460 - val_acc: 0.1400\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9443 - acc: 0.1929 - val_loss: 1.9449 - val_acc: 0.0760\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9475 - acc: 0.1071 - val_loss: 1.9440 - val_acc: 0.0790\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9439 - acc: 0.2143 - val_loss: 1.9436 - val_acc: 0.0780\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9417 - acc: 0.2071 - val_loss: 1.9432 - val_acc: 0.1030\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9404 - acc: 0.1857 - val_loss: 1.9417 - val_acc: 0.1880\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9367 - acc: 0.2071 - val_loss: 1.9387 - val_acc: 0.3150\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9447 - acc: 0.1643 - val_loss: 1.9363 - val_acc: 0.3370\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9335 - acc: 0.1571 - val_loss: 1.9333 - val_acc: 0.3900\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9288 - acc: 0.2143 - val_loss: 1.9316 - val_acc: 0.3710\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9281 - acc: 0.2714 - val_loss: 1.9297 - val_acc: 0.2630\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.9116 - acc: 0.2857 - val_loss: 1.9248 - val_acc: 0.2710\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8970 - acc: 0.3143 - val_loss: 1.9163 - val_acc: 0.2810\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8752 - acc: 0.3286 - val_loss: 1.9020 - val_acc: 0.2560\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8600 - acc: 0.3286 - val_loss: 1.8813 - val_acc: 0.2840\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8467 - acc: 0.2643 - val_loss: 1.8506 - val_acc: 0.4580\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7977 - acc: 0.3643 - val_loss: 1.8231 - val_acc: 0.5730\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7578 - acc: 0.4500 - val_loss: 1.7939 - val_acc: 0.5900\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7102 - acc: 0.4429 - val_loss: 1.7640 - val_acc: 0.5860\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6687 - acc: 0.4143 - val_loss: 1.7208 - val_acc: 0.5810\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5394 - acc: 0.5286 - val_loss: 1.6632 - val_acc: 0.6030\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5064 - acc: 0.5000 - val_loss: 1.6024 - val_acc: 0.6320\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3819 - acc: 0.5643 - val_loss: 1.5333 - val_acc: 0.6560\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3462 - acc: 0.5571 - val_loss: 1.4696 - val_acc: 0.6440\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2511 - acc: 0.6286 - val_loss: 1.3773 - val_acc: 0.6630\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1749 - acc: 0.6357 - val_loss: 1.3026 - val_acc: 0.6820\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0443 - acc: 0.6857 - val_loss: 1.1858 - val_acc: 0.7330\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9443 - acc: 0.7214 - val_loss: 1.1156 - val_acc: 0.7090\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8545 - acc: 0.7286 - val_loss: 1.1008 - val_acc: 0.6900\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8630 - acc: 0.6929 - val_loss: 1.0644 - val_acc: 0.6700\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6814 - acc: 0.8071 - val_loss: 1.0191 - val_acc: 0.6850\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6620 - acc: 0.8143 - val_loss: 0.9238 - val_acc: 0.7280\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5193 - acc: 0.8286 - val_loss: 0.8682 - val_acc: 0.7510\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5649 - acc: 0.8214 - val_loss: 0.8426 - val_acc: 0.7480\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4868 - acc: 0.8571 - val_loss: 0.8955 - val_acc: 0.7110\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4437 - acc: 0.8857 - val_loss: 0.9505 - val_acc: 0.6870\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3754 - acc: 0.8929 - val_loss: 0.9625 - val_acc: 0.6880\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3760 - acc: 0.8929 - val_loss: 0.9282 - val_acc: 0.7130\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3196 - acc: 0.9143 - val_loss: 0.8993 - val_acc: 0.7400\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2058 - acc: 0.9500 - val_loss: 0.8957 - val_acc: 0.7510\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2648 - acc: 0.9429 - val_loss: 0.8757 - val_acc: 0.7590\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1718 - acc: 0.9714 - val_loss: 0.9033 - val_acc: 0.7580\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2013 - acc: 0.9286 - val_loss: 0.9523 - val_acc: 0.7530\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.9714 - val_loss: 1.0183 - val_acc: 0.7450\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1384 - acc: 0.9571 - val_loss: 1.1207 - val_acc: 0.7410\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0901 - acc: 0.9714 - val_loss: 1.2604 - val_acc: 0.7210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc0bf6e5b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"float32\")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(training_dataset, validation_data=testing_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcce235-662b-428c-8943-23a137453730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (cotton_flower_mot)",
   "language": "python",
   "name": "kedro_cotton_flower_mot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
